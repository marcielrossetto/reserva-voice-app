// public/script.js
document.addEventListener("DOMContentLoaded", () => {
  console.log("üü¢ script.js carregado");
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  console.log("SpeechRecognition suportado?", !!SpeechRecognition);

  const startVoiceCmdBtn          = document.getElementById("startVoiceCmdBtn");
  const voiceStatus               = document.getElementById("voiceStatus");
  const transcribedTextElem       = document.getElementById("transcribedText");
  const recognizedIntentElem      = document.getElementById("recognizedIntent");
  const reservaForm               = document.getElementById("reservaForm");
  // ... (outros elementos)

  let recognition;
  let recognizing = false;
  let finalTranscript = '';

  if (SpeechRecognition) {
    recognition = new SpeechRecognition();
    recognition.lang = "pt-BR";
    recognition.continuous = true;
    recognition.interimResults = true; // Mantenha true para melhor feedback

    recognition.onstart = () => {
      console.log("üîä recognition.onstart");
      recognizing = true;
      voiceStatus.textContent = "Ouvindo... Fale e clique em 'Parar' ou aguarde o sil√™ncio."; // Atualizar instru√ß√£o
      startVoiceCmdBtn.textContent = "Parar de Ouvir";
      startVoiceCmdBtn.disabled = false;
      finalTranscript = '';
      transcribedTextElem.textContent = '...'; // Indica√ß√£o visual que est√° esperando
    };

    recognition.onresult = (event) => {
      console.log("üéôÔ∏è recognition.onresult - Evento recebido:", event); // Log mais detalhado
      let interimTranscript = '';
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        const transcriptPart = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          console.log("  -> Resultado Final:", transcriptPart);
          finalTranscript += transcriptPart + ' '; // Adiciona espa√ßo entre segmentos finais
        } else {
          console.log("  -> Resultado Intermedi√°rio:", transcriptPart);
          interimTranscript += transcriptPart;
        }
      }
      transcribedTextElem.textContent = finalTranscript.trim() + interimTranscript;
      console.log("  Texto acumulado (final):", finalTranscript.trim());
      console.log("  Texto intermedi√°rio atual:", interimTranscript);

      // Opcional: l√≥gica de timeout para parar automaticamente ap√≥s sil√™ncio
      // clearSpeechTimeout();
      // speechTimeout = setTimeout(() => {
      //   if (recognizing) {
      //     console.log("Timeout de sil√™ncio atingido, parando reconhecimento.");
      //     recognition.stop();
      //   }
      // }, 3000); // Para ap√≥s 3 segundos de sil√™ncio (ajuste conforme necess√°rio)
    };

    recognition.onerror = (event) => {
      // LOG MAIS DETALHADO DO ERRO
      console.error("‚ö†Ô∏è recognition.onerror - DETALHES DO ERRO:", event);
      console.error("   Tipo de Erro:", event.error);
      console.error("   Mensagem de Erro:", event.message);

      let userMessage = `Erro no reconhecimento: ${event.error}.`;
      if (event.error === 'no-speech') {
        userMessage = "Nenhuma fala foi detectada. Tente falar mais alto ou verifique o microfone.";
      } else if (event.error === 'audio-capture') {
        userMessage = "Problema na captura de √°udio. Verifique seu microfone e as permiss√µes.";
      } else if (event.error === 'not-allowed') {
        userMessage = "Permiss√£o para usar o microfone foi negada ou n√£o concedida.";
      } else if (event.error === 'network') {
        userMessage = "Erro de rede durante o reconhecimento. Verifique sua conex√£o.";
      }
      voiceStatus.textContent = userMessage;
      
      // Resetar estado se ocorrer um erro cr√≠tico
      if (recognizing) { // S√≥ para se estava recognizing
          // N√£o chamar recognition.stop() aqui se o erro j√° o fez,
          // mas garantir que o estado da UI seja resetado.
          recognizing = false;
          startVoiceCmdBtn.textContent = "Iniciar Comando de Voz";
          startVoiceCmdBtn.disabled = false;
      }
    };

    recognition.onend = () => {
      console.log("‚èπÔ∏è recognition.onend - Reconhecimento finalizado.");
      // clearSpeechTimeout(); // Limpa o timeout se estiver usando
      
      // S√≥ processa se estava 'recognizing' e foi parado (seja por stop() ou naturalmente)
      // E se n√£o foi um erro que j√° resetou 'recognizing'
      if (!recognizing && !startVoiceCmdBtn.disabled) { // Se j√° foi resetado por onerror, n√£o faz nada
          console.log("   onend chamado ap√≥s erro j√° tratado ou estado j√° resetado.");
          return;
      }

      recognizing = false; // Garante que est√° false
      startVoiceCmdBtn.textContent = "Iniciar Comando de Voz";
      startVoiceCmdBtn.disabled = false;

      const trimmedTranscript = finalTranscript.trim();
      if (trimmedTranscript) {
        console.log("   Texto final para processamento:", trimmedTranscript);
        transcribedTextElem.textContent = trimmedTranscript;
        voiceStatus.textContent = "Processando sua fala...";
        processVoiceCommand(trimmedTranscript);
      } else {
        console.log("   Nenhum texto final para processar.");
        // N√£o mostra "Nenhuma fala capturada" se j√° houve um erro com mensagem espec√≠fica
        if (voiceStatus.textContent.startsWith("Ouvindo") || voiceStatus.textContent.startsWith("Processando")) {
             voiceStatus.textContent = "Nenhuma fala capturada para processar.";
        }
        transcribedTextElem.textContent = transcribedTextElem.textContent || "(Nenhuma fala)"; // Mant√©m o que foi exibido se houver algo
      }
    };

    startVoiceCmdBtn.addEventListener("click", () => {
      console.log("üöÄ Bot√£o clicado. Estado recognizing atual:", recognizing);
      if (recognizing) {
        console.log("   Usu√°rio clicou para PARAR. Solicitando parada do reconhecimento...");
        recognition.stop();
      } else {
        clearAll();
        console.log("   Usu√°rio clicou para INICIAR.");
        try {
          recognition.start();
        } catch (err) {
          console.error("‚ùå Erro ao chamar recognition.start():", err);
          voiceStatus.textContent = "Erro ao iniciar. Tente novamente.";
          // N√£o precisa mexer em recognizing ou no bot√£o aqui, pois onstart/onerror cuidar√£o
        }
      }
    });

  } else {
    // ... (c√≥digo para API n√£o suportada)
  }

  // ... (fun√ß√µes processVoiceCommand, fillForm, clearAll, displayReservas, etc.)
  // Mantenha a fun√ß√£o clearAll como estava para limpar os campos
  function clearAll() {
    reservaForm.reset();
    // ... (outros resets que voc√™ tinha)
    transcribedTextElem.textContent = "";
    recognizedIntentElem.textContent = "";
    apiMessage.textContent = "";
    if (!recognizing) { // S√≥ reseta o status se n√£o estiver ouvindo
        voiceStatus.textContent = "Ocioso (clique para falar)";
    }
  }

  // ... (resto do seu script.js)
});